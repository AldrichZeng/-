#### 1、LeNet-5 on MNIST-10
|层  |剪枝率|首次测试|首次迭代|acc|Epoch|学习率|学习率衰减|batch|
|:---|:-----|:-------|:------|:-------|:------|:-----|:--------|:---------|
|    |0%    |/       |/      |0.9902  |185    | 0.001|无       |256|
|Conv|50%   |0.9861|0.9883 |0.9898  |154    |0.001 |无       |256|
|Conv|70%   |0.9833|0.9878 |0.9900  |261    |0.001 |0.1/50epoch|128|
|Conv|90%   |0.3572|0.9678 |0.9884  |206    |0.001 |0.1/50epoch|128|
|FC  |50%   |0.9832|0.9878 |0.9893  |287    |0.001 |0.1/50epoch|128|
|FC  |70%   |0.9619|0.9824 |0.9881  |273    |0.001 |0.1/50epoch|128|
|FC  |90%   |0.8973  |0.9767 |0.9865  |166    |0.001 |0.1/50epoch|128|

各层剪枝率

|卷积层|50%   |70%   |90%   |  |全连接层|50%   |70%   |90%   |
|:-----|:-----|:-----|:-----|:-|:------|:-----|:-----|:-----|
|Conv1 |0.1467|0.2400|0.4467|  |FC1    |0.4724|0.6493|0.8081|
|Conv2 |0.5221|0.7288|0.9283|  |FC2    |0.4356|0.6181|0.7792|

#### 2、AlextNet on CIFAR-10
考虑到梯度下降的收敛速度，采用Adam优化器：
`betas=(0.9, 0.999), eps=1e-08, weight_decay=0`

|层  |剪枝率|首次测试|首次迭代|acc|Epoch|学习率|学习率衰减|batch|备注|
|:---|:-----|:------|:--------|:-------|:------|:-----|:--------|:---------|:---|
|    |0%    |/      |         |0.75474 |636    | 0.001|无|128||
|Conv|50%   |0.3965 |0.4386   |0.6121  |520    |0.001 |无|128||
|Conv|90%   |0.2843 |0.4579   |0.6284  |174    |0.001 |0.1/50epoch|128|保留Conv1|
|FC  |50%   |0.6831 |0.6873   |0.7245  |283    |0.001 |0.1/50epoch|128||
|FC  |90%   |0.6857 |0.7080   |0.7508  |458    |0.001 |0.1/100epoch|128||

各层剪枝率

|卷积层剪枝|50%   |90%   |  |全连接层剪枝|50%   |90%   |
|:--------|:-----|:-----|:-|:----------|:-----|:-----|
|Conv1    |0.2784|0     |  |FC1        |0.2754|0.4299|
|Conv2    |0.5229|0.9783|  |FC2        |0.2779|0.4578|
|Conv3    |0.6058|0.9834|  |
|Conv4    |0.4534|0.8587|  |
|Conv5    |0.4569|0.8210|  |
#### 3、VGG-16_bn on CIFAR-10
|层  |剪枝率|首次测试|首次迭代|acc   |Epoch|学习率 |学习率衰减  |batch|备注|
|:---|:-----|:------|:------|:-----|:----|:-----|:----------|:----|:--|
|    |0%    |/      |       |0.7313|44   |0.001 |0.1/10epoch|16   |      |
|Conv|50%   |0.5259 |0.6743 |0.7214|45   |0.001 |0.1/5epoch |16   |      |
|Conv|90%   |      |   |  |     |       |          |16|     |
|FC|50%   |      |   |  |     |       |          |16|     |
|FC|90%   |      |   |  |     |       |          |16|     |

各层剪枝率

|层    |50%   |90%   |
|:-----|:-----|:-----|
|Conv2 |0.1963|0.4618|
|Conv3 |0.2721|0.6106|
|Conv4 |0.2771|0.6196|
|Conv5 |0.3764|0.7774|
|Conv6 |0.3815|0.7827|
|Conv7 |0.3805|0.7837|
|Conv8 |0.5148|0.9168|
|Conv9 |0.5183|0.9198|
|Conv10|0.5191|0.9201|
|Conv11|0.5185|0.9195|
|Conv12|0.5187|0.9197|
|Conv13|0.5190|0.9200|
#### 参考论文
1. 《Deep compression - Compressing Deep Neural Networks With Pruning, Tranied Quantization And Huffman Coding》
2. 《Leaning both Weights and Connections for Efficient Neural Networks》

————2019年4月28日
